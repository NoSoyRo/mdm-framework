{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d65d82",
   "metadata": {},
   "source": [
    "# Práctica 6 — Preprocesamiento de datos con Python\n",
    "\n",
    "## Objetivo\n",
    "Seleccionar las características a través de aprendizaje de máquina y Python con scikit-learn. Se pretende reducir el sobreajuste, mejorar la precisión y reducir el tiempo de entrenamiento.\n",
    "\n",
    "## Actividades a realizar:\n",
    "\n",
    "### Actividad 1: Selección de características/atributos\n",
    "a) Considere escoger las cuatro mejores características no negativas a partir del archivo pacientes.csv utilizado en la práctica anterior. Puede utilizar chi-square test y muestre los puntajes calculados para cada atributo y especifique cuales fueron los atributos seleccionados.\n",
    "\n",
    "b) Remueva atributos no relevantes a través de la eliminación recursiva de características. Utilice el algoritmo de regresión logística para seleccionar las 3 características principales. Muestre las características que quedan junto con su puntaje de ranking.\n",
    "\n",
    "c) Utilice la técnica de reducción de datos PCA (Principal Component Analysis) el cual usa algebra lineal para transformar el conjunto de datos. Considere las dimensiones y nuestro archivo transformado.\n",
    "\n",
    "d) Utilice técnicas de clasificación como Random Forest y Extra Trees para estimar la importancia de características. Muestre los puntajes de importancia por cada atributo, así como el nombre de cada atributo.\n",
    "\n",
    "### Actividad 2: Evaluar el rendimiento de los algoritmos de aprendizaje de máquina\n",
    "a) Genere muestras de entrenamiento y prueba. Considere el 67% de los datos para entrenamiento y el 33% restante para validación.\n",
    "\n",
    "b) Genere modelo por regresión logística y evalúe su precisión (accuracy) y muestrela.\n",
    "\n",
    "c) Utilice la técnica de validación cruzada para estimar el rendimiento (en términos de la media y la desviación estándar) de la regresión logística. Considere 10 segmentos de datos.\n",
    "\n",
    "d) Utilice la técnica Leave one out cross validation, usando la validación cruzada con un solo fold.\n",
    "\n",
    "### Actividad 3: Conserve el programa y los datos\n",
    "K=1. Muestre la media y la desviación estándar.\n",
    "¿Cuál es la interpretación de la media y la desviación estándar en estos dos casos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40db00",
   "metadata": {},
   "source": [
    "## Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e8b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Verificar e instalar paquetes necesarios\n",
    "packages = ['pandas','numpy','matplotlib','seaborn','scikit-learn']\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p)\n",
    "    except Exception:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', p])\n",
    "\n",
    "print('Dependencias comprobadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración para gráficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print('Librerías importadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4009d5",
   "metadata": {},
   "source": [
    "## Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo\n",
    "csv_path = 'pacientes.csv'\n",
    "\n",
    "# Nombres de columnas según práctica anterior\n",
    "cols = ['Pregnancies','PlasmaGlucose','DiastolicBP','TricepsSkinFold','TwoHourInsulin','BMI','DiabetesPedigree','Age','Outcome']\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(csv_path, header=None, names=cols)\n",
    "print('Dimensiones del dataset:', df.shape)\n",
    "print('\\nPrimeras 5 filas:')\n",
    "print(df.head())\n",
    "\n",
    "print('\\nInformación del dataset:')\n",
    "print(df.info())\n",
    "\n",
    "print('\\nEstadísticas descriptivas:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características (X) y variable objetivo (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "print('Forma de X (características):', X.shape)\n",
    "print('Forma de y (variable objetivo):', y.shape)\n",
    "print('\\nDistribución de la variable objetivo:')\n",
    "print(y.value_counts())\n",
    "print('\\nProporción de clases:')\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a8e9b",
   "metadata": {},
   "source": [
    "## Actividad 1: Selección de características/atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38296c31",
   "metadata": {},
   "source": [
    "### a) Chi-square test para seleccionar las 4 mejores características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2762f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para chi-square, necesitamos valores no negativos\n",
    "# Primero escalamos los datos para asegurar valores no negativos\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Aplicar chi-square test para seleccionar las 4 mejores características\n",
    "chi2_selector = SelectKBest(chi2, k=4)\n",
    "X_chi2 = chi2_selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# Obtener puntajes y características seleccionadas\n",
    "chi2_scores = chi2_selector.scores_\n",
    "chi2_features = X.columns[chi2_selector.get_support()]\n",
    "\n",
    "# Crear DataFrame con puntajes\n",
    "chi2_df = pd.DataFrame({\n",
    "    'Característica': X.columns,\n",
    "    'Chi2_Score': chi2_scores,\n",
    "    'Seleccionada': chi2_selector.get_support()\n",
    "}).sort_values('Chi2_Score', ascending=False)\n",
    "\n",
    "print('=== RESULTADOS CHI-SQUARE TEST ===')\n",
    "print('\\nPuntajes Chi-square para todas las características:')\n",
    "print(chi2_df)\n",
    "\n",
    "print('\\n4 mejores características seleccionadas:')\n",
    "for i, feature in enumerate(chi2_features, 1):\n",
    "    score = chi2_scores[X.columns.get_loc(feature)]\n",
    "    print(f'{i}. {feature}: {score:.4f}')\n",
    "\n",
    "print(f'\\nForma del dataset después de selección: {X_chi2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b90444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar puntajes Chi-square\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(chi2_df)), chi2_df['Chi2_Score'])\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Puntaje Chi-square')\n",
    "plt.title('Puntajes Chi-square por Característica')\n",
    "plt.xticks(range(len(chi2_df)), chi2_df['Característica'], rotation=45)\n",
    "\n",
    "# Colorear las 4 mejores características\n",
    "for i, bar in enumerate(bars):\n",
    "    if chi2_df.iloc[i]['Seleccionada']:\n",
    "        bar.set_color('red')\n",
    "    else:\n",
    "        bar.set_color('lightblue')\n",
    "\n",
    "plt.legend(['Seleccionadas', 'No seleccionadas'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83961d95",
   "metadata": {},
   "source": [
    "### b) Eliminación recursiva de características (RFE) con regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar los datos para regresión logística\n",
    "scaler_std = StandardScaler()\n",
    "X_std = scaler_std.fit_transform(X)\n",
    "\n",
    "# Crear modelo de regresión logística\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Aplicar eliminación recursiva de características para seleccionar 3\n",
    "rfe = RFE(estimator=lr, n_features_to_select=3, step=1)\n",
    "X_rfe = rfe.fit_transform(X_std, y)\n",
    "\n",
    "# Obtener características seleccionadas y rankings\n",
    "rfe_features = X.columns[rfe.support_]\n",
    "rfe_rankings = rfe.ranking_\n",
    "\n",
    "# Crear DataFrame con rankings\n",
    "rfe_df = pd.DataFrame({\n",
    "    'Característica': X.columns,\n",
    "    'Ranking': rfe_rankings,\n",
    "    'Seleccionada': rfe.support_\n",
    "}).sort_values('Ranking')\n",
    "\n",
    "print('=== RESULTADOS ELIMINACIÓN RECURSIVA DE CARACTERÍSTICAS (RFE) ===')\n",
    "print('\\nRanking de todas las características (1 = mejor):')\n",
    "print(rfe_df)\n",
    "\n",
    "print('\\n3 mejores características seleccionadas:')\n",
    "for i, feature in enumerate(rfe_features, 1):\n",
    "    print(f'{i}. {feature} (Ranking: 1)')\n",
    "\n",
    "print(f'\\nForma del dataset después de RFE: {X_rfe.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed115c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar rankings RFE\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(rfe_df)), rfe_df['Ranking'])\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Ranking RFE')\n",
    "plt.title('Rankings de Eliminación Recursiva de Características (RFE)')\n",
    "plt.xticks(range(len(rfe_df)), rfe_df['Característica'], rotation=45)\n",
    "\n",
    "# Colorear las características seleccionadas\n",
    "for i, bar in enumerate(bars):\n",
    "    if rfe_df.iloc[i]['Seleccionada']:\n",
    "        bar.set_color('green')\n",
    "    else:\n",
    "        bar.set_color('lightcoral')\n",
    "\n",
    "plt.legend(['Seleccionadas (Ranking 1)', 'No seleccionadas'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79a77b",
   "metadata": {},
   "source": [
    "### c) Análisis de Componentes Principales (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f057f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# Calcular varianza explicada\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "print('=== RESULTADOS ANÁLISIS DE COMPONENTES PRINCIPALES (PCA) ===')\n",
    "print(f'\\nDimensiones originales: {X.shape}')\n",
    "print(f'Dimensiones después de PCA: {X_pca.shape}')\n",
    "\n",
    "print('\\nVarianza explicada por cada componente principal:')\n",
    "for i, var_ratio in enumerate(explained_variance_ratio, 1):\n",
    "    print(f'PC{i}: {var_ratio:.4f} ({var_ratio*100:.2f}%)')\n",
    "\n",
    "print('\\nVarianza acumulada:')\n",
    "for i, cum_var in enumerate(cumulative_variance_ratio, 1):\n",
    "    print(f'Hasta PC{i}: {cum_var:.4f} ({cum_var*100:.2f}%)')\n",
    "\n",
    "# Determinar número óptimo de componentes (90% de varianza)\n",
    "n_components_90 = np.argmax(cumulative_variance_ratio >= 0.90) + 1\n",
    "print(f'\\nComponentes necesarios para explicar 90% de la varianza: {n_components_90}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674618e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar varianza explicada por PCA\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Varianza individual\n",
    "ax1.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.7)\n",
    "ax1.set_xlabel('Componente Principal')\n",
    "ax1.set_ylabel('Varianza Explicada')\n",
    "ax1.set_title('Varianza Explicada por Componente')\n",
    "ax1.set_xticks(range(1, len(explained_variance_ratio) + 1))\n",
    "\n",
    "# Varianza acumulada\n",
    "ax2.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, 'bo-')\n",
    "ax2.axhline(y=0.90, color='r', linestyle='--', label='90% varianza')\n",
    "ax2.set_xlabel('Número de Componentes')\n",
    "ax2.set_ylabel('Varianza Acumulada')\n",
    "ax2.set_title('Varianza Acumulada')\n",
    "ax2.set_xticks(range(1, len(cumulative_variance_ratio) + 1))\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83709ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA con número óptimo de componentes\n",
    "pca_optimal = PCA(n_components=n_components_90)\n",
    "X_pca_optimal = pca_optimal.fit_transform(X_std)\n",
    "\n",
    "print(f'Dataset transformado con PCA ({n_components_90} componentes):')\n",
    "print(f'Forma original: {X.shape}')\n",
    "print(f'Forma transformada: {X_pca_optimal.shape}')\n",
    "print(f'Varianza explicada total: {pca_optimal.explained_variance_ratio_.sum():.4f} ({pca_optimal.explained_variance_ratio_.sum()*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c06ded",
   "metadata": {},
   "source": [
    "### d) Importancia de características con Random Forest y Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c39995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "rf_importances = rf.feature_importances_\n",
    "\n",
    "# Extra Trees\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "et.fit(X, y)\n",
    "et_importances = et.feature_importances_\n",
    "\n",
    "# Crear DataFrame con importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'Característica': X.columns,\n",
    "    'RandomForest_Importance': rf_importances,\n",
    "    'ExtraTrees_Importance': et_importances\n",
    "})\n",
    "\n",
    "# Ordenar por importancia promedio\n",
    "importance_df['Promedio_Importance'] = (importance_df['RandomForest_Importance'] + \n",
    "                                       importance_df['ExtraTrees_Importance']) / 2\n",
    "importance_df = importance_df.sort_values('Promedio_Importance', ascending=False)\n",
    "\n",
    "print('=== IMPORTANCIA DE CARACTERÍSTICAS ===')\n",
    "print('\\nImportancia de características (Random Forest y Extra Trees):')\n",
    "print(importance_df)\n",
    "\n",
    "print('\\nTop 5 características más importantes (promedio):')\n",
    "top5_features = importance_df.head(5)\n",
    "for i, (_, row) in enumerate(top5_features.iterrows(), 1):\n",
    "    print(f'{i}. {row[\"Característica\"]}: {row[\"Promedio_Importance\"]:.4f}')\n",
    "    print(f'   RF: {row[\"RandomForest_Importance\"]:.4f}, ET: {row[\"ExtraTrees_Importance\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5140d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar importancias\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Random Forest\n",
    "ax1.barh(range(len(importance_df)), importance_df['RandomForest_Importance'])\n",
    "ax1.set_yticks(range(len(importance_df)))\n",
    "ax1.set_yticklabels(importance_df['Característica'])\n",
    "ax1.set_xlabel('Importancia')\n",
    "ax1.set_title('Importancia - Random Forest')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Extra Trees\n",
    "ax2.barh(range(len(importance_df)), importance_df['ExtraTrees_Importance'])\n",
    "ax2.set_yticks(range(len(importance_df)))\n",
    "ax2.set_yticklabels(importance_df['Característica'])\n",
    "ax2.set_xlabel('Importancia')\n",
    "ax2.set_title('Importancia - Extra Trees')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# Promedio\n",
    "ax3.barh(range(len(importance_df)), importance_df['Promedio_Importance'])\n",
    "ax3.set_yticks(range(len(importance_df)))\n",
    "ax3.set_yticklabels(importance_df['Característica'])\n",
    "ax3.set_xlabel('Importancia Promedio')\n",
    "ax3.set_title('Importancia Promedio')\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a8eed",
   "metadata": {},
   "source": [
    "## Actividad 2: Evaluación del rendimiento de algoritmos de aprendizaje de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0401771",
   "metadata": {},
   "source": [
    "### a) División de datos en entrenamiento (67%) y prueba (33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b280130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos: 67% entrenamiento, 33% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "print('=== DIVISIÓN DE DATOS ===')\n",
    "print(f'Tamaño total del dataset: {len(X)}')\n",
    "print(f'Tamaño de entrenamiento: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)')\n",
    "print(f'Tamaño de prueba: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)')\n",
    "\n",
    "print('\\nDistribución de clases en entrenamiento:')\n",
    "print(y_train.value_counts())\n",
    "print('\\nDistribución de clases en prueba:')\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print('\\nProporción de clases en entrenamiento:')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('\\nProporción de clases en prueba:')\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7362d46",
   "metadata": {},
   "source": [
    "### b) Modelo de regresión logística y evaluación de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar modelo de regresión logística\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_train = lr_model.predict(X_train)\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "# Calcular precisión (accuracy)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print('=== REGRESIÓN LOGÍSTICA - EVALUACIÓN ===')\n",
    "print(f'Precisión en entrenamiento: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)')\n",
    "print(f'Precisión en prueba: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')\n",
    "\n",
    "# Mostrar coeficientes del modelo\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Característica': X.columns,\n",
    "    'Coeficiente': lr_model.coef_[0]\n",
    "}).sort_values('Coeficiente', key=abs, ascending=False)\n",
    "\n",
    "print('\\nCoeficientes del modelo (ordenados por magnitud):')\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c910e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar coeficientes\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(coefficients_df)), coefficients_df['Coeficiente'])\n",
    "plt.yticks(range(len(coefficients_df)), coefficients_df['Característica'])\n",
    "plt.xlabel('Coeficiente')\n",
    "plt.title('Coeficientes del Modelo de Regresión Logística')\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360d3c1",
   "metadata": {},
   "source": [
    "### c) Validación cruzada con 10 segmentos (K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada con 10 folds\n",
    "cv_scores = cross_val_score(lr_model, X_std, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print('=== VALIDACIÓN CRUZADA (10-FOLD) ===')\n",
    "print(f'Precisión de cada fold:')\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f'Fold {i:2d}: {score:.4f} ({score*100:.2f}%)')\n",
    "\n",
    "print(f'\\nEstadísticas de validación cruzada:')\n",
    "print(f'Media: {cv_scores.mean():.4f} ({cv_scores.mean()*100:.2f}%)')\n",
    "print(f'Desviación estándar: {cv_scores.std():.4f} ({cv_scores.std()*100:.2f}%)')\n",
    "print(f'Mínimo: {cv_scores.min():.4f} ({cv_scores.min()*100:.2f}%)')\n",
    "print(f'Máximo: {cv_scores.max():.4f} ({cv_scores.max()*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b47721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados de validación cruzada\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, len(cv_scores) + 1), cv_scores)\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Media: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Precisión')\n",
    "plt.title('Precisión por Fold (10-Fold CV)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(cv_scores)\n",
    "plt.ylabel('Precisión')\n",
    "plt.title('Distribución de Precisión (10-Fold CV)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3152858",
   "metadata": {},
   "source": [
    "### d) Leave-One-Out Cross Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2315ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Out Cross Validation\n",
    "loo = LeaveOneOut()\n",
    "loo_scores = cross_val_score(lr_model, X_std, y, cv=loo, scoring='accuracy')\n",
    "\n",
    "print('=== LEAVE-ONE-OUT CROSS VALIDATION (LOOCV) ===')\n",
    "print(f'Número total de iteraciones: {len(loo_scores)}')\n",
    "print(f'Número de predicciones correctas: {loo_scores.sum():.0f}')\n",
    "print(f'Número de predicciones incorrectas: {len(loo_scores) - loo_scores.sum():.0f}')\n",
    "\n",
    "print(f'\\nEstadísticas de LOOCV:')\n",
    "print(f'Media: {loo_scores.mean():.4f} ({loo_scores.mean()*100:.2f}%)')\n",
    "print(f'Desviación estándar: {loo_scores.std():.4f} ({loo_scores.std()*100:.2f}%)')\n",
    "\n",
    "# Comparar con validación cruzada de 10 folds\n",
    "print(f'\\n=== COMPARACIÓN DE MÉTODOS DE VALIDACIÓN ===')\n",
    "print(f'10-Fold CV - Media: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}')\n",
    "print(f'LOOCV      - Media: {loo_scores.mean():.4f}, Std: {loo_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc77d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparación de métodos de validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "methods = ['10-Fold CV', 'LOOCV']\n",
    "means = [cv_scores.mean(), loo_scores.mean()]\n",
    "stds = [cv_scores.std(), loo_scores.std()]\n",
    "\n",
    "plt.bar(methods, means, yerr=stds, capsize=10, alpha=0.7)\n",
    "plt.ylabel('Precisión Media')\n",
    "plt.title('Comparación de Métodos de Validación')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    plt.text(i, mean + std + 0.01, f'{mean:.4f}±{std:.4f}', \n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores, loo_scores], labels=methods)\n",
    "plt.ylabel('Precisión')\n",
    "plt.title('Distribución de Precisión por Método')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e1dcf",
   "metadata": {},
   "source": [
    "## Actividad 3: K=1 y interpretación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f109828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada con K=1 (equivalente a LOOCV)\n",
    "print('=== VALIDACIÓN CON K=1 ===')\n",
    "print('Nota: K=1 es equivalente a Leave-One-Out Cross Validation')\n",
    "print(f'Media: {loo_scores.mean():.4f}')\n",
    "print(f'Desviación estándar: {loo_scores.std():.4f}')\n",
    "\n",
    "print('\\n=== INTERPRETACIÓN DE RESULTADOS ===')\n",
    "print('\\n1. MEDIA:')\n",
    "print(f'   - 10-Fold CV: {cv_scores.mean():.4f}')\n",
    "print(f'   - LOOCV (K=1): {loo_scores.mean():.4f}')\n",
    "print('\\n   Interpretación:')\n",
    "print('   La media representa la precisión promedio esperada del modelo.')\n",
    "print('   Ambos métodos dan resultados muy similares, lo que indica')\n",
    "print('   que el modelo es estable y consistente.')\n",
    "\n",
    "print('\\n2. DESVIACIÓN ESTÁNDAR:')\n",
    "print(f'   - 10-Fold CV: {cv_scores.std():.4f}')\n",
    "print(f'   - LOOCV (K=1): {loo_scores.std():.4f}')\n",
    "print('\\n   Interpretación:')\n",
    "print('   La desviación estándar mide la variabilidad del rendimiento.')\n",
    "print('   - LOOCV tiene mayor variabilidad porque cada iteración usa')\n",
    "print('     solo una muestra para prueba.')\n",
    "print('   - 10-Fold CV es más estable al usar múltiples muestras por fold.')\n",
    "print('   - Una desviación menor indica mayor confiabilidad en la estimación.')\n",
    "\n",
    "print('\\n3. RECOMENDACIÓN:')\n",
    "if cv_scores.std() < loo_scores.std():\n",
    "    print('   10-Fold CV es preferible por su menor variabilidad y menor')\n",
    "    print('   costo computacional, manteniendo una estimación confiable.')\n",
    "else:\n",
    "    print('   Ambos métodos son comparables en términos de variabilidad.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f898543",
   "metadata": {},
   "source": [
    "## Resumen de resultados y conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b000fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('RESUMEN DE RESULTADOS - PRÁCTICA 6')\n",
    "print('=' * 60)\n",
    "\n",
    "print('\\n1. SELECCIÓN DE CARACTERÍSTICAS:')\n",
    "print(f'   Chi-square (4 mejores): {list(chi2_features)}')\n",
    "print(f'   RFE (3 mejores): {list(rfe_features)}')\n",
    "print(f'   PCA: {n_components_90} componentes para 90% varianza')\n",
    "print(f'   Top 3 por importancia: {list(importance_df.head(3)[\"Característica\"])}')\n",
    "\n",
    "print('\\n2. RENDIMIENTO DEL MODELO:')\n",
    "print(f'   Precisión en prueba: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')\n",
    "print(f'   10-Fold CV: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')\n",
    "print(f'   LOOCV: {loo_scores.mean():.4f} ± {loo_scores.std():.4f}')\n",
    "\n",
    "print('\\n3. CARACTERÍSTICAS MÁS IMPORTANTES:')\n",
    "top3_importance = importance_df.head(3)\n",
    "for i, (_, row) in enumerate(top3_importance.iterrows(), 1):\n",
    "    print(f'   {i}. {row[\"Característica\"]}: {row[\"Promedio_Importance\"]:.4f}')\n",
    "\n",
    "print('\\n4. CONCLUSIONES:')\n",
    "print('   - El modelo muestra un rendimiento consistente entre diferentes')\n",
    "print('     métodos de validación.')\n",
    "print('   - Las técnicas de selección identifican características clave')\n",
    "print('     para la predicción de diabetes.')\n",
    "print('   - PCA permite reducir dimensionalidad manteniendo información relevante.')\n",
    "print('   - La validación cruzada confirma la generalización del modelo.')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('PRÁCTICA 6 COMPLETADA EXITOSAMENTE')\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
